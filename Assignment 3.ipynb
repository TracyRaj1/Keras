{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import pip\n\ntry:\n    __import__('keras')\nexcept ImportError:\n    pip.main(['install', 'keras']) \n    \ntry:\n    __import__('ibmiotf')\nexcept ImportError:\n    pip.main(['install', 'ibmiotf']) "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nimport sklearn\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.layers import LSTM\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Activation\nimport pickle\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport ibmiotf.application\nimport sys\nfrom queue import Queue\nimport pandas as pd\nimport json\n%matplotlib inline"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!rm watsoniotp.*\n!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.healthy.phase_aligned.pickle\n!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.broken.phase_aligned.pickle\n!mv watsoniotp.healthy.phase_aligned.pickle watsoniotp.healthy.pickle\n!mv watsoniotp.broken.phase_aligned.pickle watsoniotp.broken.pickle"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "data_healthy = pickle.load(open('watsoniotp.healthy.pickle', 'rb'), encoding='latin1')\ndata_broken = pickle.load(open('watsoniotp.broken.pickle', 'rb'), encoding='latin1')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "data_healthy = data_healthy.reshape(3000,3)\ndata_broken = data_broken.reshape(3000,3)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "fig = plt.figure()\nax = fig.gca(projection='3d')\n\nax.plot(data_healthy[:,0], data_healthy[:,1], data_healthy[:,2],lw=0.5)\nax.set_xlabel(\"X Axis\")\nax.set_ylabel(\"Y Axis\")\nax.set_zlabel(\"Z Axis\")\nax.set_title(\"Lorenz Attractor\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "fig = plt.figure()\nax = fig.gca(projection='3d')\n\nax.plot(data_broken[:,0], data_broken[:,1], data_broken[:,2],lw=0.5)\nax.set_xlabel(\"X Axis\")\nax.set_ylabel(\"Y Axis\")\nax.set_zlabel(\"Z Axis\")\nax.set_title(\"Lorenz Attractor\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "data_healthy_fft = np.fft.fft(data_healthy)\ndata_broken_fft = np.fft.fft(data_broken)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print (data_healthy_fft.shape)\nprint (data_healthy_fft)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nsize = len(data_healthy_fft)\nax.plot(range(0,size), data_healthy_fft[:,0].real, '-', color='blue', animated = True, linewidth=1)\nax.plot(range(0,size), data_healthy_fft[:,1].real, '-', color='red', animated = True, linewidth=1)\nax.plot(range(0,size), data_healthy_fft[:,2].real, '-', color='green', animated = True, linewidth=1)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nsize = len(data_healthy_fft)\nax.plot(range(0,size), data_broken_fft[:,0].real, '-', color='blue', animated = True, linewidth=1)\nax.plot(range(0,size), data_broken_fft[:,1].real, '-', color='red', animated = True, linewidth=1)\nax.plot(range(0,size), data_broken_fft[:,2].real, '-', color='green', animated = True, linewidth=1)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def scaleData(data):\n    # normalize features\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    return scaler.fit_transform(data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "data_healthy_scaled = scaleData(data_healthy_fft)\ndata_broken_scaled = scaleData(data_broken_fft)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "data_healthy_scaled.shape = (3, 3000)\ndata_broken_scaled.shape = (3, 3000)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!rm -f rklib.py\n!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/coursera/ai/rklib.py"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from rklib import submit, submitAll\nkey = \"4vkB9vnrEee8zg4u9l99rA\"\nall_parts = [\"O5cR9\",\"0dXlH\",\"ZzEP8\"]\n\nemail = \"tracy.raj@outlook.com\""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#### your code here ###\ndim = 3000\nsamples = 6"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "part = \"O5cR9\"\nsecret = \"8M2eU4YdNnE3PaEF\"\n\nsubmitAll(email, secret, key, dict((p, json.dumps({}) if p != part else json.dumps({\"dim\": dim, \"samples\": samples})) for p in all_parts))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "class LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        sys.stdout.write(str(logs.get('loss'))+str(', '))\n        sys.stdout.flush()\n        self.losses.append(logs.get('loss'))\n        \nlr = LossHistory()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "number_of_neurons_layer1 = 3000 #### your code here ###\nnumber_of_neurons_layer2 = 3000 #### your code here ###\nnumber_of_neurons_layer3 = 3000 #### your code here ###\nnumber_of_epochs = 100 #### your code here ###"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "parts_data = {}\nparts_data[\"0dXlH\"] = json.dumps({\"number_of_neurons_layer1\": number_of_neurons_layer1, \"number_of_neurons_layer2\": number_of_neurons_layer2, \"number_of_neurons_layer3\": number_of_neurons_layer3, \"number_of_epochs\": number_of_epochs})\nparts_data[\"O5cR9\"] = json.dumps({\"dim\": dim, \"samples\": samples})\nparts_data[\"ZzEP8\"] = None \n                                 \n                                 \nsecret = \"8M2eU4YdNnE3PaEF\"\n\n\nsubmitAll(email, secret, key, parts_data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# design network\n\nmodel = Sequential()\nmodel.add(Dense(number_of_neurons_layer1,input_shape=(dim, ), activation='relu'))\nmodel.add(Dense(number_of_neurons_layer2, activation='relu'))\nmodel.add(Dense(number_of_neurons_layer3, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam')\n\ndef train(data,label):\n    model.fit(#### your code here ###, #### your code here ###, epochs=number_of_epochs, batch_size=72, validation_data=(data, label), verbose=0, shuffle=True,callbacks=[lr])\n\ndef score(data):\n    return model.#### your code here ###(data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from keras import backend as K\n\nK.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "label_healthy = np.repeat(1,3)\nlabel_healthy.shape = (3,1)\nlabel_broken = np.repeat(0,3)\nlabel_broken.shape = (3,1)\n\ntrain_healthy = np.hstack((data_healthy_scaled,label_healthy))\ntrain_broken = np.hstack((data_broken_scaled,label_broken))\ntrain_both = np.vstack((train_healthy,train_broken))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pd.DataFrame(train_healthy)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pd.DataFrame(train_broken)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pd.DataFrame(train_both)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "features = train_both[:,:3000]\nlabels = train_both[:,: -1]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "train(features,labels)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "fig, ax = plt.subplots(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\nsize = len(lr.losses)\nax.plot(range(0,size), lr.losses, '-', color='blue', animated = True, linewidth=1)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "score(data_healthy_scaled)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "score(data_broken_scaled)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "options = {\"org\": \"tzxf7h\", \"id\": \"anything\", \"auth-method\": \"apikey\", \"auth-key\": \"a-tzxf7h-aldwfg1q4o\", \"auth-token\": \"Kr(aDjgKj_?NW9T@!o\"}\nclient = ibmiotf.application.Client(options)\nclient.connect()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "q = Queue(7000)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def myEventCallback(event):\n    sample = event.data\n    point = [sample[\"x\"], sample[\"y\"],sample[\"z\"]]\n    q.put(point)\n\nclient.deviceEventCallback = myEventCallback\nclient.subscribeToDeviceEvents(\"0.16.2\", \"lorenz\", \"osc\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "submit_work = True ###_YOUR_CODE_GOES_HERE_### => set to True in case you want to submit to the grader\nparts_data = {}\nparts_data[\"0dXlH\"] = json.dumps({\"number_of_neurons_layer1\": number_of_neurons_layer1, \"number_of_neurons_layer2\": number_of_neurons_layer2, \"number_of_neurons_layer3\": number_of_neurons_layer3, \"number_of_epochs\": number_of_epochs})\nparts_data[\"O5cR9\"] = json.dumps({\"dim\": dim, \"samples\": samples})\n\n                                 \n                                 \nsecret = \"8M2eU4YdNnE3PaEF\""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def doNN(data):\n    global submit_work\n    data_fft = np.fft.fft(data)\n    data_scaled = scaleData(data_fft)\n    data_scaled_reshaped = data_scaled\n    data_scaled_reshaped.shape = (3, 3000)\n    prediction = str(np.sum(score(data_scaled_reshaped))/3)\n    print (\"Prediction: %s, publishing...\" % (prediction))\n    myData={'healthy' : prediction}\n    client.publishEvent(\"0.16.2\", \"lorenz\", \"status\", \"json\", myData)\n    if submit_work:\n        submit_work = False\n        parts_data[\"ZzEP8\"] = json.dumps(myData)\n        submitAll(email, secret, key, parts_data)\n        print (\"Submitting to grader: %s\" % (json.dumps(myData)))\n    print (\"Done\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\nwhile True:\n    while not q.empty():\n        sys.stdout.write('.')\n        sys.stdout.flush()\n        point = q.get()\n        try:\n            data\n        except NameError:\n            data = np.array(point)\n        else:\n            data = np.append(data,point)\n        if data.size>=9000:\n            data = np.reshape(data,(3000,3))\n            print (\"Sending window downstream to the neural network...\")\n            doNN(data)\n            print (\"Training finished...\")\n            del data"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "del data"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}